{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "----------\n",
      "torch.Size([64]) torch.Size([64, 10])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-825029e56ea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;36m0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from ptflops import get_model_complexity_info\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# 构建 transform\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "# 加载数据\n",
    "data_train = datasets.MNIST(root = \"./data/\",\n",
    "                            transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "data_test = datasets.MNIST(root=\"./data/\",\n",
    "                           transform = transform,\n",
    "                           train = False)\n",
    "\n",
    "# 创建数据 loader\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                batch_size = 64,\n",
    "                                                shuffle = True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size = 128,\n",
    "                                               shuffle = True)\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(torch.nn.Conv2d(1,4,kernel_size=3,stride=1,padding=1), # in 28*28*1 out 28*28*4\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(stride=2,kernel_size=2)) # out 14*14*4\n",
    "        \n",
    "        self.conv2 = torch.nn.Sequential(torch.nn.Conv2d(4,8,kernel_size=3,stride=1,padding=0), # in 14*14*4 out 12*12*8\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(stride=2,kernel_size=2)) # out 6*6*8\n",
    "        self.conv3 = torch.nn.Sequential(torch.nn.Conv2d(8,16,kernel_size=3,stride=1,padding=0), # in 6*6*8 out 4*4*16\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(stride=2,kernel_size=2)) # out 2*2*16\n",
    "        self.conv4 = torch.nn.Sequential(torch.nn.Conv2d(16,10,kernel_size=1,stride=1,padding=0), # in 2*2*16 out 2*2*10\n",
    "                                         torch.nn.AvgPool2d(stride=2,kernel_size=2)) # out 1*1*10\n",
    "#         self.dense = torch.nn.Sequential(torch.nn.Dropout(p=0.25),\n",
    "#                                          torch.nn.Linear(1*1*32, 10),\n",
    "#                                          torch.nn.Softmax())\n",
    "#         self.dense = torch.nn.Sequential(torch.nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(-1, 1*1*10)\n",
    "#         x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "if(use_gpu):\n",
    "    model = model.cuda()\n",
    "    cost = cost.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "###########################################################################################\n",
    "# list(model.named_parameters())\n",
    "# list(model.named_buffers())\n",
    "# print(next(model.conv1.modules())[0])\n",
    "parameters_to_prune = []\n",
    "for module in model.modules():\n",
    "    if hasattr(module, 'weight'):\n",
    "        parameters_to_prune.append((module, 'weight'))\n",
    "# parameters_to_prune = (\n",
    "#     (next(model.conv1.modules())[0], 'weight'),\n",
    "#     (next(model.conv2.modules())[0], 'weight'),\n",
    "#     (next(model.conv3.modules())[0], 'weight'),\n",
    "#     (next(model.conv4.modules())[0], 'weight'),\n",
    "# )\n",
    "        \n",
    "# prune.global_unstructured(\n",
    "#     tuple(parameters_to_prune),\n",
    "#     pruning_method=prune.L1Unstructured,\n",
    "#     amount=0.2,\n",
    "# )\n",
    "\n",
    "# ops, params = get_model_complexity_info(model, (1, 28, 28), as_strings=True, print_per_layer_stat=True, verbose=True)\n",
    "\n",
    "# print(ops, params)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    print(\"-\"*10)\n",
    "    for data in data_loader_train:\n",
    "        X_train, y_train = data\n",
    "        X_train, y_train = Variable(X_train), Variable(y_train)\n",
    "        if (use_gpu):\n",
    "            X_train,y_train = X_train.cuda(),y_train.cuda()\n",
    "        outputs = model(X_train)\n",
    "        if(use_gpu):\n",
    "            outputs = outputs.cpu()\n",
    "        _,pred = torch.max(outputs.data, 1)\n",
    "        optimizer.zero_grad()\n",
    "        print(y_train.shape, outputs.shape)\n",
    "        0/0\n",
    "        loss = cost(outputs, y_train.cpu())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data.item()\n",
    "        running_correct += torch.sum(pred == y_train.cpu().data)\n",
    "    testing_correct = 0\n",
    "    for data in data_loader_test:\n",
    "        X_test, y_test = data\n",
    "        X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "        if (use_gpu):\n",
    "            X_test,y_test = X_test.cuda(),y_test.cuda()\n",
    "        outputs = model(X_test)\n",
    "        if (use_gpu):\n",
    "            outputs = outputs.cpu()\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        testing_correct += torch.sum(pred == y_test.cpu().data)\n",
    "    print(\"Loss is:{:.4f}, Train Accuracy is:{:.4f}%, Test Accuracy is:{:.4f}%\".format(1.*running_loss/len(data_train),\n",
    "                                                                                      100.*running_correct/len(data_train),\n",
    "                                                                                      100.*testing_correct/len(data_test)))\n",
    "torch.save(model.state_dict(), \"model_parameter.pkl\")\n",
    "\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(\n",
    "            torch.sum(next(model.conv1.modules())[0].weight == 0)\n",
    "            + torch.sum(next(model.conv2.modules())[0].weight == 0)\n",
    "            + torch.sum(next(model.conv3.modules())[0].weight == 0)\n",
    "            + torch.sum(next(model.conv4.modules())[0].weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            next(model.conv1.modules())[0].weight.nelement()\n",
    "            + next(model.conv2.modules())[0].weight.nelement()\n",
    "            + next(model.conv3.modules())[0].weight.nelement()\n",
    "            + next(model.conv4.modules())[0].weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# print(model.state_dict())\n",
    "dummy_input = torch.randn(1, 1, 28, 28, device='cuda')\n",
    "torch.onnx.export(model, dummy_input, \"mnist.onnx\", verbose=False, input_names=['input_1'], output_names=['output_1'])\n",
    "print(\"train ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
